{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELPAC_file_path = '/ADS-599B/Raw_Files/ELPAC.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import files from Excel file containing ELPAC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/ADS-599B/Raw_Files/ELPAC.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/oscargil/Library/CloudStorage/GoogleDrive-gil.oscar@gmail.com/My Drive/Masters of Science in Applied Data Science (University of San Diego)/2022 - S6 - Fall Courses/Capstone Project - ADS 599B/GitHub/ADS-599B/Code Library Folder/1_Deidentify.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oscargil/Library/CloudStorage/GoogleDrive-gil.oscar%40gmail.com/My%20Drive/Masters%20of%20Science%20in%20Applied%20Data%20Science%20%28University%20of%20San%20Diego%29/2022%20-%20S6%20-%20Fall%20Courses/Capstone%20Project%20-%20ADS%20599B/GitHub/ADS-599B/Code%20Library%20Folder/1_Deidentify.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Import ELPAC data into dataframes\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oscargil/Library/CloudStorage/GoogleDrive-gil.oscar%40gmail.com/My%20Drive/Masters%20of%20Science%20in%20Applied%20Data%20Science%20%28University%20of%20San%20Diego%29/2022%20-%20S6%20-%20Fall%20Courses/Capstone%20Project%20-%20ADS%20599B/GitHub/ADS-599B/Code%20Library%20Folder/1_Deidentify.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m elpac1718 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(\u001b[39mopen\u001b[39;49m(ELPAC_file_path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m), sheet_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2017-2018\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oscargil/Library/CloudStorage/GoogleDrive-gil.oscar%40gmail.com/My%20Drive/Masters%20of%20Science%20in%20Applied%20Data%20Science%20%28University%20of%20San%20Diego%29/2022%20-%20S6%20-%20Fall%20Courses/Capstone%20Project%20-%20ADS%20599B/GitHub/ADS-599B/Code%20Library%20Folder/1_Deidentify.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Drop identified columns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oscargil/Library/CloudStorage/GoogleDrive-gil.oscar%40gmail.com/My%20Drive/Masters%20of%20Science%20in%20Applied%20Data%20Science%20%28University%20of%20San%20Diego%29/2022%20-%20S6%20-%20Fall%20Courses/Capstone%20Project%20-%20ADS%20599B/GitHub/ADS-599B/Code%20Library%20Folder/1_Deidentify.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m elpac1718\u001b[39m.\u001b[39mdrop(elpac1718\u001b[39m.\u001b[39mcolumns[[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m10\u001b[39m]], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/ADS-599B/Raw_Files/ELPAC.xlsx'"
     ]
    }
   ],
   "source": [
    "# Import ELPAC data into dataframes\n",
    "elpac1718 = pd.read_excel(open(ELPAC_file_path, 'rb'), sheet_name='2017-2018', dtype=str)\n",
    "\n",
    "\n",
    "# Drop identified columns\n",
    "elpac1718.drop(elpac1718.columns[[0, 1, 5, 7, 8, 9, 10]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ELPAC data into dataframes\n",
    "elpac1819 = pd.read_excel(open(ELPAC_file_path, 'rb'), sheet_name='2018-2019', dtype=str)\n",
    "\n",
    "\n",
    "# Drop identified columns\n",
    "elpac1819.drop(elpac1819.columns[[0, 1, 5, 7, 8, 9, 10]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ELPAC data into dataframes\n",
    "elpac1920 = pd.read_excel(open(ELPAC_file_path, 'rb'), sheet_name='2019-2020', dtype=str)\n",
    "\n",
    "\n",
    "# Drop identified columns\n",
    "elpac1920.drop(elpac1920.columns[[0, 1, 5, 7, 8, 9, 10]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ELPAC data into dataframes\n",
    "elpac2021 = pd.read_excel(open(ELPAC_file_path, 'rb'), sheet_name='2020-2021', dtype=str)\n",
    "\n",
    "\n",
    "# Drop identified columns\n",
    "elpac2021.drop(elpac2021.columns[[0, 1, 6, 8, 9, 10, 11]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ELPAC data into dataframes\n",
    "elpac2122 = pd.read_excel(open(ELPAC_file_path, 'rb'), sheet_name='2021-2022', dtype=str)\n",
    "\n",
    "\n",
    "# Drop identified columns\n",
    "elpac2122.drop(elpac2122.columns[[1, 5, 7, 8, 9, 17, 19, 21, 54, 55, 56, 57, 58, 61, 62, 63, 64, 70, 71, 72, 73, 79, 80, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a unique list of all SSIDs and assign them the Pandas Dataframe index number as their de-identified number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame of SSIDs to de-identify\n",
    "ssids = pd.DataFrame(pd.concat([elpac1718.elpac_2018_ssid, elpac1819.elpac_2019_ssid, elpac1920.elpac_2020_ssid, elpac2021.elpac_2021_ssid, elpac2122.SSID], axis=0))\n",
    "\n",
    "# Unique SSID values\n",
    "ssid_deidentify = pd.DataFrame(ssids[0].unique())\n",
    "\n",
    "ssid_deidentify.columns = ['SSID']\n",
    "\n",
    "# Assign Data frame index as de-identified ID\n",
    "ssid_deidentify['Stu_deID'] =  ssid_deidentify.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local file to have as reference to Stu_deID\n",
    "ssid_deidentify.to_csv('Raw_Files/ssid_deidentify.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge de-identified ID into ELPAC dataframes, then dropped the SSID field containing the real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in de-identier\n",
    "elpac1718 = elpac1718.merge(ssid_deidentify, how=\"inner\", left_on='elpac_2018_ssid', right_on='SSID')\n",
    "\n",
    "# Drop SSID columns\n",
    "elpac1718.drop(elpac1718.columns[[3, 57]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in de-identier\n",
    "elpac1819 = elpac1819.merge(ssid_deidentify, how=\"inner\", left_on='elpac_2019_ssid', right_on='SSID')\n",
    "\n",
    "# Drop SSID columns\n",
    "elpac1819.drop(elpac1819.columns[[3, 54]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in de-identier\n",
    "elpac1920 = elpac1920.merge(ssid_deidentify, how=\"inner\", left_on='elpac_2020_ssid', right_on='SSID')\n",
    "\n",
    "# Drop SSID columns\n",
    "elpac1920.drop(elpac1920.columns[[3, 79]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in de-identier\n",
    "elpac2021 = elpac2021.merge(ssid_deidentify, how=\"inner\", left_on='elpac_2021_ssid', right_on='SSID')\n",
    "\n",
    "# Drop SSID columns\n",
    "elpac2021.drop(elpac2021.columns[[4, 120]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in de-identier\n",
    "elpac2122 = elpac2122.merge(ssid_deidentify, how=\"inner\", left_on='SSID', right_on='SSID')\n",
    "\n",
    "# Drop SSID columns\n",
    "elpac2122.drop(elpac2122.columns[[3]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add AcademicYear column to each ELPAC file, to join into attendance files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add AcademicYear column\n",
    "elpac1718['AcademicYear'] = '2017-2018'\n",
    "elpac1819['AcademicYear'] = '2018-2019'\n",
    "elpac1920['AcademicYear'] = '2019-2020'\n",
    "elpac2021['AcademicYear'] = '2020-2021'\n",
    "elpac2122['AcademicYear'] = '2021-2022'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify features to keep from ELPAC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset ELPAC files\n",
    "elpac1718 = elpac1718.iloc[:,[56, 57, 3, 4, 7, 10, 11]]\n",
    "elpac1819 = elpac1819.iloc[:,[53, 54, 3, 4, 7, 10, 11]]\n",
    "elpac1920 = elpac1920.iloc[:,[78, 79, 3, 6, 7, 8, 9]]\n",
    "elpac2021 = elpac2021.iloc[:,[119, 120, 4, 5, 8, 9, 10]]\n",
    "elpac2122 = elpac2122[['Stu_deID', 'AcademicYear','DateofBirth', 'CALPADSGrade', 'FinalTestCompletedDate', 'OverallScaleScore', 'OverallPL']]\n",
    "\n",
    "# Rename columns\n",
    "elpac_columns = ['Stu_deID', 'AcademicYear', 'DOB', 'GradeLevel', 'TestDate', 'OverallScore', 'OverallLevel']\n",
    "\n",
    "elpac1718.columns = elpac_columns\n",
    "elpac1819.columns = elpac_columns\n",
    "elpac1920.columns = elpac_columns\n",
    "elpac2021.columns = elpac_columns\n",
    "elpac2122.columns = elpac_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data conversions - DOB to datetime\n",
    "elpac1718['DOB'] = pd.to_datetime(elpac1718['DOB'])\n",
    "elpac1819['DOB'] = pd.to_datetime(elpac1819['DOB'])\n",
    "elpac1920['DOB'] = pd.to_datetime(elpac1920['DOB'])\n",
    "elpac2021['DOB'] = pd.to_datetime(elpac2021['DOB'])\n",
    "elpac2122['DOB'] = pd.to_datetime(elpac2122['DOB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data conversions - TestDate to datetime\n",
    "elpac1718['TestDate'] = pd.to_datetime(elpac1718['TestDate'])\n",
    "elpac1819['TestDate'] = pd.to_datetime(elpac1819['TestDate'])\n",
    "elpac1920['TestDate'] = pd.to_datetime(elpac1920['TestDate'])\n",
    "elpac2021['TestDate'] = pd.to_datetime(elpac2021['TestDate'])\n",
    "elpac2122['TestDate'] = pd.to_datetime(elpac2122['TestDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data conversions - GradeLevel clean up, eliminate extra zero, convert KN to 0\n",
    "elpac1718['GradeLevel'] = elpac1718.GradeLevel.replace('KN', '0').astype(int)\n",
    "elpac1819['GradeLevel'] = elpac1819.GradeLevel.replace('KN', '0').astype(int)\n",
    "elpac1920['GradeLevel'] = elpac1920.GradeLevel.replace('KN', '0').astype(int)\n",
    "elpac2021['GradeLevel'] = elpac2021.GradeLevel.replace('KN', '0').astype(int)\n",
    "elpac2122['GradeLevel'] = elpac2122.GradeLevel.replace('KN', '0').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elpac1718['OverallScore'] = elpac1718.OverallScore.replace('NS',0).fillna(0).astype(int)\n",
    "elpac1819['OverallScore'] = elpac1819.OverallScore.replace('NS',0).fillna(0).astype(int)\n",
    "elpac1920['OverallScore'] = elpac1920.OverallScore.replace('NS',0).fillna(0).astype(int)\n",
    "elpac2021['OverallScore'] = elpac2021.OverallScore.replace('NS',0).fillna(0).astype(int)\n",
    "elpac2122['OverallScore'] = elpac2122.OverallScore.replace('NS',0).fillna(0).astype(int)\n",
    "\n",
    "elpac1718['OverallLevel'] = elpac1718.OverallLevel.replace('NS',0).fillna(0).astype(int)\n",
    "elpac1819['OverallLevel'] = elpac1819.OverallLevel.replace('NS',0).fillna(0).astype(int)\n",
    "elpac1920['OverallLevel'] = elpac1920.OverallLevel.replace('NS',0).fillna(0).astype(int)\n",
    "elpac2021['OverallLevel'] = elpac2021.OverallLevel.replace('NS',0).fillna(0).astype(int)\n",
    "elpac2122['OverallLevel'] = elpac2122.OverallLevel.replace('NS',0).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Elpac file containing all years\n",
    "elpac = pd.concat([elpac1718, elpac1819, elpac1920, elpac2021, elpac2122], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering Ideas\n",
    "\n",
    "* Day of the week\n",
    "* Grade Level + percentage of days enrolled (so for example, 4th grade would not be represented by a '4', instead, by '4.80' - a 4th grader who attended 80% of the time)\n",
    "* Number of Levels a student progressed from previous ELPAC (17-18 a student who scores a Level 1, then in 18-19 scoed a Level 3; the student progressed 2 levels)\n",
    "* Age of Student at time of test\n",
    "* Teacher information (years teaching)\n",
    "* Total in Household\n",
    "* Household income\n",
    "* Homeless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# TestDayName\n",
    "elpac['TestDayName'] = elpac.TestDate.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age at time of test\n",
    "elpac['TestAge'] = (elpac.TestDate - elpac.DOB) / np.timedelta64(1, 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elpac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attendance Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attendance_file_path = 'Raw_Files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load attendance data\n",
    "att_1718 = pd.read_csv(Attendance_file_path + 'STAS_ODS_1718.txt', sep='^', dtype=str, header=None)\n",
    "att_1819 = pd.read_csv(Attendance_file_path + 'STAS_ODS_1819.txt', sep='^', dtype=str, header=None)\n",
    "att_1920 = pd.read_csv(Attendance_file_path + 'STAS_ODS_1920.txt', sep='^', dtype=str, header=None)\n",
    "att_2021 = pd.read_csv(Attendance_file_path + 'STAS_ODS_2021.txt', sep='^', dtype=str, header=None)\n",
    "att_2122 = pd.read_csv(Attendance_file_path + 'STAS_ODS_2122.txt', sep='^', dtype=str, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to keep\n",
    "att_1718 = att_1718.iloc[:,[5, 6, 14, 15]].fillna(0.00)\n",
    "att_1819 = att_1819.iloc[:,[5, 6, 14, 15]].fillna(0.00)\n",
    "att_1920 = att_1920.iloc[:,[5, 6, 14, 15]].fillna(0.00)\n",
    "att_2021 = att_2021.iloc[:,[5, 6, 14, 15]].fillna(0.00)\n",
    "att_2122 = att_2122.iloc[:,[5, 6, 14, 15]].fillna(0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column names\n",
    "att_columns = ['AcademicYear', 'SSID', 'ExpectedAttendanceDays', 'DaysAttended']\n",
    "\n",
    "att_1718.columns = att_columns\n",
    "att_1819.columns = att_columns\n",
    "att_1920.columns = att_columns\n",
    "att_2021.columns = att_columns\n",
    "att_2122.columns = att_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data conversions\n",
    "att_1718['ExpectedAttendanceDays'] = att_1718.ExpectedAttendanceDays.astype(float)\n",
    "att_1819['ExpectedAttendanceDays'] = att_1819.ExpectedAttendanceDays.astype(float)\n",
    "att_1920['ExpectedAttendanceDays'] = att_1920.ExpectedAttendanceDays.astype(float)\n",
    "att_2021['ExpectedAttendanceDays'] = att_2021.ExpectedAttendanceDays.astype(float)\n",
    "att_2122['ExpectedAttendanceDays'] = att_2122.ExpectedAttendanceDays.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data conversions\n",
    "att_1718['DaysAttended'] = att_1718.DaysAttended.astype(float)\n",
    "att_1819['DaysAttended'] = att_1819.DaysAttended.astype(float)\n",
    "att_1920['DaysAttended'] = att_1920.DaysAttended.astype(float)\n",
    "att_2021['DaysAttended'] = att_2021.DaysAttended.astype(float)\n",
    "att_2122['DaysAttended'] = att_2122.DaysAttended.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Att into one file\n",
    "att = pd.concat([att_1718, att_1819, att_1920, att_2021, att_2122], axis =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student demographics and Teacher data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaation from SQL query in Data Server with file name \"CAPSTONE SQL code.sql\"\n",
    "teacher_stuDemographics = pd.read_csv('Raw_Files/teacher_stuDemographics.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Schoolname values - only present in the 2021-2022 file\n",
    "schools_deidentify = pd.DataFrame(teacher_stuDemographics.SchoolName.unique())\n",
    "\n",
    "schools_deidentify.columns = ['SchoolName']\n",
    "\n",
    "# Assign Data frame index as de-identified ID\n",
    "schools_deidentify['School_deID'] =  schools_deidentify.index\n",
    "\n",
    "# Merge in de-identier\n",
    "teacher_stuDemographics = teacher_stuDemographics.merge(schools_deidentify, how=\"inner\", left_on='SchoolName', right_on='SchoolName')\n",
    "\n",
    "# Drop school name column\n",
    "teacher_stuDemographics.drop(teacher_stuDemographics.columns[[2]], axis=1, inplace=True)\n",
    "\n",
    "# Create local file to have as reference to School_deID\n",
    "schools_deidentify.to_csv('Raw_Files/schools_deidentify.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate deidentified student ID\n",
    "teacher_stuDemographics = teacher_stuDemographics.merge(ssid_deidentify, how=\"inner\", left_on='SSID', right_on='SSID')\n",
    "\n",
    "# Drop student ID column\n",
    "teacher_stuDemographics.drop(teacher_stuDemographics.columns[[1]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update elpac dataframe\n",
    "elpac = elpac.merge(teacher_stuDemographics, how=\"inner\", left_on=('AcademicYear', 'Stu_deID'), right_on=('AcademicYear', 'Stu_deID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = sqlite3.connect('Raw_Files/db.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes into sql\n",
    "att.to_sql(\"att\", cnn, if_exists='replace')\n",
    "ssid_deidentify.to_sql(\"ssid\", cnn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///Raw_Files/db.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select s.Stu_deID, AcademicYear, sum(ExpectedAttendanceDays) as ExpectedAttendanceDays, sum(DaysAttended) as DaysAttended\n",
    ", sum(DaysAttended) / sum(ExpectedAttendanceDays) as AttendedPct\n",
    ", sum(ExpectedAttendanceDays) / 180.0 as EnrolledPct\n",
    "from att as a \n",
    "join ssid as s \n",
    "    on a.SSID = s.SSID\n",
    "group by a.SSID, a.AcademicYear\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL results to dataframe\n",
    "att_sql = '''\n",
    "select s.Stu_deID, AcademicYear, sum(ExpectedAttendanceDays) as ExpectedAttendanceDays, sum(DaysAttended) as DaysAttended\n",
    ", sum(DaysAttended) / sum(ExpectedAttendanceDays) as AttendedPct\n",
    ", sum(ExpectedAttendanceDays) / 180.0 as EnrolledPct\n",
    "from att as a \n",
    "join ssid as s \n",
    "    on a.SSID = s.SSID\n",
    "group by a.SSID, a.AcademicYear\n",
    "'''\n",
    "\n",
    "att_df = pd.read_sql_query(att_sql, cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge attendance into ELPAC file\n",
    "elpac = elpac.merge(att_df, how='inner', left_on=('Stu_deID', 'AcademicYear'), right_on=('Stu_deID', 'AcademicYear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "elpac['GradeEnrolledPct'] = elpac.GradeLevel + elpac.EnrolledPct.replace(1.0,.999999)\n",
    "\n",
    "elpac['GradeAttendedPct'] = elpac.GradeLevel + elpac.AttendedPct.replace(1.0,.999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort columns for final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elpac = elpac.iloc[:,[1, 0, 17, 3, 2, 8, 9, 10, 11, 12, 13, 7, 4, 5, 6, 18, 19, 20, 21, 22, 23, 15, 14, 16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export ELPAC file to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elpac.to_csv('Data Folder/elpac.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('ADS500B')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d26887a0ce0c3c4488c5c94af6ff26a975a652bca174f379a81267199556a29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
